nb_episodes: 100000
steps: 2000
train_for: 5
train_every: 1
players: [0]
env:
  action_space: 5
  grid_width: 10
  grid_length: 10
  wall_pixels: 1
  snake_pixels: 1
  pixel_size: 8
  grid_in_rgb: 1
  bg_color:
    id: 0
    rgb: (0, 0, 0)
  wall_color:
    id: 1
    rgb: (255, 0, 0)
  sh_color:
    id: 2
    rgb: (247, 77, 255)
  sb_color:
    id: 3
    rgb: (255, 228, 33)
  f_color:
    id: 4
    rgb: (2, 213, 27)
buffer:
  buffer_size: 1e6
  batch_size: 32
  unroll_steps: 5
  td_steps: 10
  reanalize: 1
  stacked_frame: 16
  support_size: 10
  action_space: 5
  current_game_folder: games_batch_0
  max_nb_of_g_per_folder: 1000
model:
  depth: 128
  reduced_depth: 32
  stacked_frame: 4
  blocks: 8
  support_size: 10
  use_downsampling: 1
  action_space: 5
  value_layers: [128, 32]
  policy_layers: [128, 32]
  reward_layers: [128, 32]
  learning_rate: 0.001
  adam_beta_1: 0.9
  adam_beta_2: 0.999
  adam_epsilon: 1e-07
  value_loss_weight: 0.25
  model_path: log/model
game:
  discount: 0.997
mcts:
  players: [0]
  num_simulations: 50
  support_size: 10
  max_moves: 2000
  root_dirichlet_alpha: 0.25
  root_exploration_fraction: 0.25
  pb_c_base: 19652
  pb_c_init: 1.25
  action_space: 5
  action_pos: [0,1,2,3,4]
  discount: 0.997
para:
  size: 128
